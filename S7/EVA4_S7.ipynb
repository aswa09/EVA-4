{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "EVA4_S7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswa09/EVA-4/blob/master/S7/EVA4_S7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCx6T90YBLzJ",
        "colab_type": "text"
      },
      "source": [
        "#Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yVpodAMpoCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjt4e2TpoCk",
        "colab_type": "text"
      },
      "source": [
        "## Get Train and Test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_test():\n",
        "\n",
        "  classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
        "    'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "  SEED = 1\n",
        "\n",
        "  # CUDA?\n",
        "  cuda = torch.cuda.is_available()\n",
        "  print(\"CUDA Available?\", cuda)\n",
        "\n",
        "  # For reproducibility\n",
        "  torch.manual_seed(SEED)\n",
        "\n",
        "  if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "  # dataloader arguments - something you'll fetch these from cmdprmt\n",
        "  dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                      download=True, transform=transform)\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, **dataloader_args)\n",
        "  testloader = torch.utils.data.DataLoader(testset, **dataloader_args)\n",
        "\n",
        "  return trainloader, testloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28OpHA_LpoCq",
        "colab_type": "text"
      },
      "source": [
        "##Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjLwLLQpoCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dropout_value = 0.1\n",
        "\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        ) # In: 32x32x3 | Out: 32x32x32 | RF: 3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        ) # In: 32x32x32 | Out: 32x32x32 | RF: 5\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # In: 32x32x32 | Out: 16x16x12 | RF: 6\n",
        "\n",
        "        # Depthwise Separable Convolution\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, groups=32, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        ) # In: 16x16x32 | Out: 16x16x32 | RF: 10\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        ) # In: 16x16x32 | Out: 16x16x64 | RF: 14\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # In: 16x16x32 | Out: 8x8x32 | RF: 16\n",
        "\n",
        "        # Dilated Convolution\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        ) # In: 8x8x64 | Out: 8x8x64 | RF: 24\n",
        "        \n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout_value)\n",
        "        ) # In: 8x8x64 | Out: 8x8x128 | RF: 32\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        ) # In: 8x8x128 | Out: 1x1x128 | RF: 40\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)\n",
        "            # nn.ReLU() NEVER!\n",
        "        ) # In: 1x1x128 | Out: 1x1x10 | RF: 56\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-odOrhdpoC2",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkuRfo1IpoC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    L1 = 0\n",
        "    #loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    if L1 > 0:\n",
        "      l1_crit = nn.L1Loss(size_average = False).to(device)\n",
        "      l1_loss = 0\n",
        "      for param in model.parameters():\n",
        "        zero_vector = torch.rand_like(param) * 0\n",
        "        l1_loss += l1_crit(param, zero_vector)\n",
        "      factor = 0.0005\n",
        "      loss += factor * l1_loss\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "  return train_losses,train_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGH_5lMtAx3l",
        "colab_type": "text"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MednzpF9AyGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "  try:\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_losses=[]\n",
        "    test_acc = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_losses.append(test_loss)\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "  except Exception as e:\n",
        "    print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + \" \" + type(e).__name__ + \" \" + str(e))\n",
        "    sys.exit(1)\n",
        "  return test_losses,test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaruGoc1Cb-E",
        "colab_type": "text"
      },
      "source": [
        "##Plotting Test Accuracies and Test Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaJQRZ7JCcO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_acc_loss(test_losses, test_acc):\n",
        "  try:\n",
        "  \n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(15,10))\n",
        "    fig.suptitle('Test Loss and Test Accuracy for the models', fontsize=16)\n",
        "    ax1.plot(test_losses[0])\n",
        "\n",
        "    ax1.set_title(\"Test Loss\")\n",
        "    \n",
        "    ax2.plot(test_acc[0])\n",
        "\n",
        "    ax2.set_title(\"Test Accuracy\")\n",
        "   \n",
        "    plt.savefig('acc_vs_loss.jpg')\n",
        "    plt.show()\n",
        "  except Exception as e:\n",
        "        print('Error on line {}'.format(sys.exc_info()[-1].tb_lineno) + \" \" + type(e).__name__ + \" \" + str(e))\n",
        "        sys.exit(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLrvL_fHpoC5",
        "colab_type": "text"
      },
      "source": [
        "##Main function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nizbsvw9poC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  !pip install torchsummary\n",
        "  from torchsummary import summary\n",
        "  from tqdm import tqdm\n",
        "  \n",
        "  train_loader, test_loader = get_train_test()\n",
        "\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  print(device)\n",
        "\n",
        "  model = Net().to(device)\n",
        "  summary(model, input_size=(3, 32, 32))\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "  EPOCHS=2\n",
        " \n",
        "  test_loss=[]\n",
        "  test_accuracy=[]\n",
        "  for epoch in range(EPOCHS):\n",
        "      print(\"EPOCH:\", epoch + 1)\n",
        "      train_losses,train_acc=train(model, device, train_loader, optimizer, epoch=EPOCHS)\n",
        "      test_losses,test_acc=test(model, device, test_loader)\n",
        "\n",
        "      test_loss.append(test_losses)\n",
        "      test_accuracy.append(test_acc)\n",
        "  \n",
        "  plot_acc_loss(test_losses,test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT7wFVqpBFn1",
        "colab_type": "text"
      },
      "source": [
        "##Calling Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZev8Z-x-T8f",
        "colab_type": "code",
        "outputId": "4dc69103-29a2-4c0a-e3ac-53f50e43bf65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  from tqdm import tqdm\n",
        "  if hasattr(tqdm, '_instances'):\n",
        "    tqdm._instances.clear()\n",
        "  main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "CUDA Available? True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           9,216\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "              ReLU-7           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-8           [-1, 32, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]             288\n",
            "      BatchNorm2d-10           [-1, 32, 16, 16]              64\n",
            "             ReLU-11           [-1, 32, 16, 16]               0\n",
            "          Dropout-12           [-1, 32, 16, 16]               0\n",
            "           Conv2d-13           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-14           [-1, 64, 16, 16]             128\n",
            "             ReLU-15           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-16             [-1, 64, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 6, 6]          36,864\n",
            "      BatchNorm2d-18             [-1, 64, 6, 6]             128\n",
            "             ReLU-19             [-1, 64, 6, 6]               0\n",
            "          Dropout-20             [-1, 64, 6, 6]               0\n",
            "           Conv2d-21            [-1, 128, 6, 6]          73,728\n",
            "      BatchNorm2d-22            [-1, 128, 6, 6]             256\n",
            "             ReLU-23            [-1, 128, 6, 6]               0\n",
            "          Dropout-24            [-1, 128, 6, 6]               0\n",
            "AdaptiveAvgPool2d-25            [-1, 128, 1, 1]               0\n",
            "           Conv2d-26             [-1, 10, 1, 1]           1,280\n",
            "================================================================\n",
            "Total params: 141,376\n",
            "Trainable params: 141,376\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.68\n",
            "Params size (MB): 0.54\n",
            "Estimated Total Size (MB): 3.23\n",
            "----------------------------------------------------------------\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=1.1840957403182983 Batch_id=390 Accuracy=49.77: 100%|██████████| 391/391 [00:11<00:00, 32.89it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1800, Accuracy: 5658/10000 (56.58%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.8185805082321167 Batch_id=390 Accuracy=65.83: 100%|██████████| 391/391 [00:11<00:00, 33.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.9210, Accuracy: 6771/10000 (67.71%)\n",
            "\n",
            "Error on line 4 NameError name 'plt' is not defined\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWUyRbnkBm2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}